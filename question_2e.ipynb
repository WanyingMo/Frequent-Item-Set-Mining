{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eadb6121-5d2a-4169-bba0-86ac8b64e424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((('DAI23334', 'ELE92920'), 'DAI62779'), 1.0), ((('DAI31081', 'GRO85051'), 'FRO40251'), 1.0), ((('DAI55911', 'GRO85051'), 'FRO40251'), 1.0), ((('DAI62779', 'DAI88079'), 'FRO40251'), 1.0), ((('DAI75645', 'GRO85051'), 'FRO40251'), 1.0)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from operator import itemgetter\n",
    "conf = SparkConf()\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "lines = sc.textFile(\"browsing.txt\")\n",
    "\n",
    "products = lines.flatMap(lambda x: x.split(\" \")).countByValue()\n",
    "pro_100={}\n",
    "for key,value in products.items():#single element which appears more than 100\n",
    "    if value>=100:\n",
    "         pro_100.setdefault(str(key),int(value))\n",
    "            \n",
    "def split_line(line):#split every line in to separate elements\n",
    "    pros=[]\n",
    "    for pro in line.split():\n",
    "        pros.append(str(pro))\n",
    "    return pros\n",
    "def pair2_product(p):\n",
    "    pairs=[]\n",
    "    n=len(p)\n",
    "    for i in range(0,n-1):\n",
    "        for j in range(i+1,n):\n",
    "            if (p[i] in pro_100) and (p[j] in pro_100):\n",
    "                pairs.append(((p[i],p[j]),1))\n",
    "                pairs.append(((p[j],p[i]),1))\n",
    "    return pairs\n",
    "\n",
    "pro=lines.map(split_line)\n",
    "p_pairs=pro.flatMap(pair2_product)\n",
    "counted=p_pairs.groupByKey() \\\n",
    "    .map(lambda x: (x[0], sum(x[1])))\\\n",
    "    .filter(lambda x: x[1] >= 100) \n",
    "counted=counted.collect()\n",
    "key=[]\n",
    "value=[]\n",
    "for i in counted:\n",
    "    key.append(i[0])\n",
    "    value.append(i[1])\n",
    "pair_100=zip(key,value)\n",
    "pair_100=dict(pair_100)\n",
    "\n",
    "def pair3_product(p):\n",
    "    pairs=[]\n",
    "    n=len(p)\n",
    "    for i in range(0,n-2):\n",
    "        for j in range(i+1,n-1):\n",
    "            for k in range(j+1,n):\n",
    "                #if (((p[i],p[j]) in pair_100) and (p[k] in pro_100)):\n",
    "                #    pairs.append((((p[i],p[j]),p[k]),1))\n",
    "                #if (((p[j],p[k]) in pair_100) and (p[i] in pro_100)):\n",
    "                #    pairs.append((((p[j],p[k]),p[i]),1))\n",
    "                #if (((p[j],p[k]) in pair_100) and (p[i] in pro_100)):\n",
    "                #    pairs.append((((p[i],p[k]),p[j]),1))\n",
    "                if (((p[i],p[j]) in pair_100) and (p[k] in pro_100)) or (((p[i],p[k]) in pair_100) and (p[j] in pro_100)) or (((p[j],p[k]) in pair_100) and (p[i] in pro_100)):\n",
    "                    pairs.append(((p[i],p[j],p[k]),1))\n",
    "                    pairs.append(((p[i],p[k],p[j]),1))\n",
    "                    pairs.append(((p[j],p[i],p[k]),1))\n",
    "                    pairs.append(((p[j],p[k],p[i]),1))\n",
    "                    pairs.append(((p[k],p[j],p[i]),1))\n",
    "                    pairs.append(((p[k],p[i],p[j]),1))\n",
    "    return pairs\n",
    "def confidence(p):\n",
    "    sup1=int(pair_100[(p[0][0],p[0][1])])\n",
    "    conf1=p[1]/sup1\n",
    "    sup2=int(pair_100[(p[0][0],p[0][2])])\n",
    "    conf2=p[1]/sup2\n",
    "    sup3=int(pair_100[(p[0][1],p[0][2])])\n",
    "    conf3=p[1]/sup3\n",
    "    return ((((p[0][0],p[0][1]),p[0][2]),conf1),(((p[0][0],p[0][2]),p[0][1]),conf2),(((p[0][1],p[0][2]),p[0][0]),conf3))\n",
    "\n",
    "p_pairs3=pro.flatMap(pair3_product)\n",
    "#counted2=p_pairs2.groupByKey() \\#count(((pi,pj),pk),1)\n",
    "#    .filter(lambda x: 2 not in x[1]) \\\n",
    "#    .map(lambda x: (x[0], sum(x[1])))\\\n",
    "#    .filter(lambda x: x[1] >= 100)\n",
    "counted3=p_pairs3.groupByKey() \\\n",
    "    .map(lambda x: (x[0], sum(x[1])))\\\n",
    "    .filter(lambda x: x[1] >= 100)\n",
    "result=counted3.flatMap(confidence)\n",
    "#result.saveAsTextFile(\"result5.txt\")\n",
    "result=result.collect()\n",
    "result=list(set(result))\n",
    "result=sorted(result,key=lambda x: (-x[1], x[0][0][0],x[0][0][1],x[0][1]))\n",
    "print(result[0:5])\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2c612d-6eb9-4330-b5ca-df5459e9647d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "* Spark 3 in Python 3.8",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
